#! /usr/bin/env python3

from ultralytics import YOLO
from collections import defaultdict
import cv2
import argparse
import numpy as np
import socket
import threading
import struct
import time
import os
from http.server import BaseHTTPRequestHandler, HTTPServer
from queue import Queue
import asyncio
from threading import Thread

class MJPEGStreamHandler(BaseHTTPRequestHandler):
    def __init__(self, request, client_address, server, frame_queue):
        self.frame_queue = frame_queue
        self.streaming_started = False  # Flag to track streaming start
        super().__init__(request, client_address, server)

    def do_GET(self):
        if self.path == '/':
            if not self.streaming_started:
                # Start streaming only on the first request
                self.start_streaming()

            self.send_response(200)
            self.send_header('Content-type', 'text/html')  # Set content type to text/html
            self.end_headers()

            # Send the initial HTML content
            self.wfile.write(b'<html><body>')
            self.wfile.write(b'<h1>SpesRobotics Strim</h1>')
            self.wfile.write(b'<div id="video-container"><img id="video-feed" src="/video_stream" /></div>')
            self.wfile.write(b'<button onclick="saveImage()">Save Image</button>')
            
            self.wfile.write(b'''<script>
                                    document.getElementById("video-feed").src = "/video_stream"; 
                                    function resetConnection() { 
                                        var img = document.getElementById("video-feed"); 
                                        img.src = "/video_stream?" + new Date().getTime(); }
                                    
                                                                    function saveImage() {
                                        var xhr = new XMLHttpRequest();
                                        xhr.open("GET", "/save_image", true);
                                        console.log("Image 1111111111");
                                        xhr.onreadystatechange = function() {
                                            console.log("Image222222222222");
                                            if (xhr.readyState == 4) {
                                                if (xhr.status == 200) {
                                                    console.log("Image saved successfully");
                                                } else {
                                                    console.error("Failed to save image");
                                                }
                                            }
                                        };
                                        xhr.send();

                                    }

                                </script>''')
            self.wfile.write(b'</body></html>')
        elif self.path == '/video_stream':
            # Handle video stream as before
            self.send_response(200)
            self.send_header('Content-type', 'multipart/x-mixed-replace; boundary=frame')
            self.end_headers()

            while True:
                try:
                    frame = self.frame_queue.get()

                    _, img_encoded = cv2.imencode('.jpg', frame)
                    frame_bytes = img_encoded.tobytes()

                    # Send the frame to the browser
                    self.send_header('Content-type', 'image/jpeg')
                    self.send_header('Content-length', len(frame_bytes))
                    self.end_headers()
                    self.wfile.write(frame_bytes)
                    self.wfile.write(b'\r\n--frame\r\n')
                except Exception as e:
                    print("Exception: ", e)

        elif self.path == '/save_image':
            # self.save_image()
            Thread(target=self.save_image).start()
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b'Image saving started')

        else:
            self.send_response(404)
            self.end_headers()
            self.wfile.write(b'Not Found')
    

    def save_image(self):
        try:
            print("Saving image...")
            frame = self.frame_queue.get()
            cv2.imwrite("slika.jpg", frame)
            print("Image saved successfully")
        except Exception as e:
            print(f"Error saving image: {e}")


    def start_streaming(self):
        self.streaming_started = True



class UDPStreamer:
    BUFFER_SIZE = 1024

    def __init__(self, port):
        self.__sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.__sock.bind(('0.0.0.0', port))
        self.__client = None

        self.__thread = threading.Thread(target=self.__listen)
        self.__running = True
        self.__thread.start()

    def __listen(self):
        while self.__running:
            _, client = self.__sock.recvfrom(1024)
            if self.__client != client:
                self.__client = client
                print('Client connected')

    def send(self, data):
        if self.__client is None:
            return
        self.__sock.sendto(data, self.__client)

    def send_yolo_detections(self, results, timestamp_sec, timestamp_nsec):
        boxes = results[0].boxes.xywh.cpu()
        track_ids = results[0].boxes.id.int().cpu().tolist()
        classes = results[0].boxes.cls.int().cpu().tolist()
        confs = results[0].boxes.conf.cpu().tolist()
        image_height, image_width = results[0].orig_img.shape[:2]

        message = struct.pack('>H', len(boxes))

        for box, track_id, class_, conf in zip(boxes, track_ids, classes, confs):
            x, y, w, h = box
            class_ = int(class_)
            instance = int(class_ * 1e6) + int(track_id)
            center_x = int(x)
            center_y = int(y)
            width = int(w)
            height = int(h)
            conf = int(conf * 100)
            message += struct.pack(
                '>HIHHHHBqqHH',
                class_,
                instance,
                center_x,
                center_y,
                width,
                height,
                conf,
                timestamp_sec,
                timestamp_nsec,
                image_width,
                image_height,
            )

            print(
                f'Detected {results[0].names[class_]}[{instance}] at ({center_x}, {center_y})'
            )

        self.send(message)

    def close(self):
        self.__running = False
        self.__thread.join()
        self.__sock.close()


def get_annotated_frame(results, track_history):
    boxes = results[0].boxes.xywh.cpu()
    track_ids = results[0].boxes.id.int().cpu().tolist()
    annotated_frame = results[0].plot()

    for box, track_id in zip(boxes, track_ids):
        x, y, w, h = box
        track = track_history[track_id]
        track.append((float(x), float(y)))
        if len(track) > 30:
            track.pop(0)

        points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))
        cv2.polylines(
            annotated_frame,
            [points],
            isClosed=False,
            color=(230, 230, 230),
            thickness=10,
        )

    return annotated_frame


class OpencvCameraReader:
    def __init__(self, source):
        self.__capture = cv2.VideoCapture(source)

    def is_open(self):
        return self.__capture.isOpened()

    def read(self):
        timestamp = time.time()
        timestamp_sec = int(time.time())
        timestamp_nsec = int((timestamp - timestamp_sec) * 1e9)
        success, image = self.__capture.read()
        return success, image, (timestamp_sec, timestamp_nsec)

    def close(self):
        self.__capture.release()

# def start_stream_server(frame_queue):
#     server = HTTPServer(('0.0.0.0', 8080), lambda *args, **kwargs: MJPEGStreamHandler(*args, **kwargs, frame_queue=frame_queue))
#     print(f'Starting streaming server on http://0.0.0.0:8080/')
#     server.serve_forever()

def start_stream_server(frame_queue):
    server = HTTPServer(('0.0.0.0', 8080), lambda *args, **kwargs: MJPEGStreamHandler(*args, **kwargs, frame_queue=frame_queue))
    print(f'Starting streaming server on http://0.0.0.0:8080/')

    # Pokrećemo server u zasebnom thread-u
    server_thread = Thread(target=server.serve_forever)
    server_thread.daemon = True
    server_thread.start()

    # Čekamo da server završi (ovo će se dogoditi kada zatvorimo aplikaciju)
    server_thread.join()


class ROSCameraReader:
    def __init__(self) -> None:
        import rclpy
        from sensor_msgs.msg import Image
        from cv_bridge import CvBridge

        rclpy.init()
        self.__node = rclpy.create_node('ros_camera_reader')
        self.__bridge = CvBridge()
        self.__message = None
        self.__subscriber = self.__node.create_subscription(
            Image, '/image_raw', self.__callback, 1
        )
        self.__thread = threading.Thread(
            target=rclpy.spin, args=(self.__node,))
        self.__thread.start()

    def __callback(self, msg):
        self.__message = msg

    def is_open(self):
        return True

    def read(self):
        while self.__message is None:
            time.sleep(0.01)
        image = self.__bridge.imgmsg_to_cv2(self.__message, 'bgr8')
        timestamp = self.__message.header.stamp
        self.__message = None
        return True, image, (timestamp.sec, timestamp.nanosec)

    def close(self):
        self.__thread.join()
        self.__node.destroy_node()


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--model', type=str, default='yolov8n.pt', help='Path to a model'
    )
    parser.add_argument('--source', type=str, default='0', help='Camera index')
    parser.add_argument(
        '--show-detections', type=bool, default=False, help='Show detections'
    )
    parser.add_argument('--port', type=int, default=5000, help='UDP port')
    parser.add_argument('--verbose', type=bool, default=False, help='Verbose')
    args, _ = parser.parse_known_args()

    track_history = defaultdict(lambda: [])

    model = YOLO(args.model)

    streamer = UDPStreamer(args.port)

    image_reader = OpencvCameraReader(
        int(args.source)) if args.source != 'ros' else ROSCameraReader()
    if not image_reader.is_open():
        print('Unable to open camera')
        exit(1)
    
    frame_queue = Queue(maxsize=1)
    # Create a separate thread for the HTTP server
    
    server_thread = threading.Thread(target=start_stream_server, args=(frame_queue,))
    server_thread.daemon = True
    server_thread.start()

    while True:
        success, image, (timestamp_sec, timestamp_nsec) = image_reader.read()
        if not success:
            break

        results = model.track(
            image,
            persist=True,
            verbose=args.verbose,
            tracker=os.path.join(
                os.path.dirname(os.path.realpath(__file__)), 'tracker.yaml'
            ),
        )
        if results[0].boxes.id is None:
            frame_queue.put(image)    
            continue
        else:
            frame_queue.put(get_annotated_frame(results, track_history))
        streamer.send_yolo_detections(
            results,
            timestamp_sec=timestamp_sec,
            timestamp_nsec=timestamp_nsec,
        )
        
        if args.show_detections:
            annotated_frame = get_annotated_frame(results, track_history)
            cv2.imshow('image', annotated_frame)
            if cv2.waitKey(1) == ord('q'):
                break

    image_reader.close()
    streamer.close()

    if args.show_detections:
        cv2.destroyAllWindows()


if __name__ == '__main__':
    main()
